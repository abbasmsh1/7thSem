{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>\n",
    "Custom Model\n",
    "</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3753288185326071\n",
      "Epoch 2, Loss: 0.3296852434862433\n",
      "Epoch 3, Loss: 0.32172863615060493\n",
      "Epoch 4, Loss: 0.3209098515786286\n",
      "Epoch 5, Loss: 0.3196634255751247\n",
      "Epoch 6, Loss: 0.30535163847750335\n",
      "Epoch 7, Loss: 0.30697402130937046\n",
      "Epoch 8, Loss: 0.3083557003769733\n",
      "Epoch 9, Loss: 0.3021257318674022\n",
      "Epoch 10, Loss: 0.30161121252190226\n",
      "Epoch 11, Loss: 0.3002430551224925\n",
      "Epoch 12, Loss: 0.30799874533002425\n",
      "Epoch 13, Loss: 0.3021688620771063\n",
      "Epoch 14, Loss: 0.29760451576080466\n",
      "Epoch 15, Loss: 0.30770622203853604\n",
      "Epoch 16, Loss: 0.3027622269875055\n",
      "Epoch 17, Loss: 0.30312761006232863\n",
      "Epoch 18, Loss: 0.30098555444092334\n",
      "Epoch 19, Loss: 0.2897601078254029\n",
      "Epoch 20, Loss: 0.2929577011144183\n",
      "Epoch 21, Loss: 0.2878304340817782\n",
      "Epoch 22, Loss: 0.28942535006091497\n",
      "Epoch 23, Loss: 0.29199744299137237\n",
      "Epoch 24, Loss: 0.28504278804400596\n",
      "Epoch 25, Loss: 0.2828099105894898\n",
      "Epoch 26, Loss: 0.2915983877688314\n",
      "Epoch 27, Loss: 0.29363576993588564\n",
      "Epoch 28, Loss: 0.292184005094152\n",
      "Epoch 29, Loss: 0.28947007263487823\n",
      "Epoch 30, Loss: 0.2931079105941447\n",
      "Epoch 31, Loss: 0.2900823160666682\n",
      "Epoch 32, Loss: 0.30402164119659303\n",
      "Epoch 33, Loss: 0.2950879541056085\n",
      "Epoch 34, Loss: 0.27778977734905747\n",
      "Epoch 35, Loss: 0.2927712132378748\n",
      "Epoch 36, Loss: 0.28234634083803034\n",
      "Epoch 37, Loss: 0.28921060120084474\n",
      "Epoch 38, Loss: 0.2774805976389509\n",
      "Epoch 39, Loss: 0.2758574449339515\n",
      "Epoch 40, Loss: 0.2892833369469\n",
      "Epoch 41, Loss: 0.2893690589753059\n",
      "Epoch 42, Loss: 0.28017434321316204\n",
      "Epoch 43, Loss: 0.2810858336820866\n",
      "Epoch 44, Loss: 0.2879366963949456\n",
      "Epoch 45, Loss: 0.2742388798027787\n",
      "Epoch 46, Loss: 0.2861620735162419\n",
      "Epoch 47, Loss: 0.2812487584812269\n",
      "Epoch 48, Loss: 0.28574907874556943\n",
      "Epoch 49, Loss: 0.270993639320329\n",
      "Epoch 50, Loss: 0.2778702617335552\n",
      "Epoch 51, Loss: 0.28209292041103196\n",
      "Epoch 52, Loss: 0.2668077621373545\n",
      "Epoch 53, Loss: 0.26903228017200326\n",
      "Epoch 54, Loss: 0.2793204421731453\n",
      "Epoch 55, Loss: 0.2656419303988325\n",
      "Epoch 56, Loss: 0.275586033309204\n",
      "Epoch 57, Loss: 0.2712324925847213\n",
      "Epoch 58, Loss: 0.2733587242462101\n",
      "Epoch 59, Loss: 0.2743076560984203\n",
      "Epoch 60, Loss: 0.26843643772890136\n",
      "Epoch 61, Loss: 0.2710812508637522\n",
      "Epoch 62, Loss: 0.2691332611937394\n",
      "Epoch 63, Loss: 0.2794507075114986\n",
      "Epoch 64, Loss: 0.2623395595879581\n",
      "Epoch 65, Loss: 0.24721136197212348\n",
      "Epoch 66, Loss: 0.28347952067713533\n",
      "Epoch 67, Loss: 0.25906852915966155\n",
      "Epoch 68, Loss: 0.25357764800075705\n",
      "Epoch 69, Loss: 0.25485704139179677\n",
      "Epoch 70, Loss: 0.2728435511053384\n",
      "Epoch 71, Loss: 0.260007562607416\n",
      "Epoch 72, Loss: 0.2630371352913876\n",
      "Epoch 73, Loss: 0.26912613353626214\n",
      "Epoch 74, Loss: 0.2633639643432704\n",
      "Epoch 75, Loss: 0.27088564215054856\n",
      "Epoch 76, Loss: 0.25496670684420597\n",
      "Epoch 77, Loss: 0.2435026644420945\n",
      "Epoch 78, Loss: 0.254039363752095\n",
      "Epoch 79, Loss: 0.2682510751739255\n",
      "Epoch 80, Loss: 0.2510707793743471\n",
      "Epoch 81, Loss: 0.2506258952012459\n",
      "Epoch 82, Loss: 0.25955802487507185\n",
      "Epoch 83, Loss: 0.24876336484011885\n",
      "Epoch 84, Loss: 0.25966877394033855\n",
      "Epoch 85, Loss: 0.24687104773288765\n",
      "Epoch 86, Loss: 0.26678399032598094\n",
      "Epoch 87, Loss: 0.2576782083464267\n",
      "Epoch 88, Loss: 0.2524605377241415\n",
      "Epoch 89, Loss: 0.2483767454173125\n",
      "Epoch 90, Loss: 0.25063728912972383\n",
      "Epoch 91, Loss: 0.24372997645939593\n",
      "Epoch 92, Loss: 0.2572318542243213\n",
      "Epoch 93, Loss: 0.2501310431381141\n",
      "Epoch 94, Loss: 0.23862930602605237\n",
      "Epoch 95, Loss: 0.24237648239463125\n",
      "Epoch 96, Loss: 0.252377319734779\n",
      "Epoch 97, Loss: 0.2405307508007966\n",
      "Epoch 98, Loss: 0.22341519588999256\n",
      "Epoch 99, Loss: 0.22794485271849485\n",
      "Epoch 100, Loss: 0.24735525467858882\n",
      "Finished Training\n",
      "Accuracy on test data: 94.51%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Step 1: Data Loading and Preprocessing\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = r'Data\\archive\\Master Folder'\n",
    "image_datasets = {x: datasets.ImageFolder(root=data_dir, transform=data_transforms[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Step 2: Define a Custom CNN Model\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 56 * 56)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CustomCNN(len(class_names))\n",
    "\n",
    "# Step 3: Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Step 4: Training Loop\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(dataloaders['train'])}\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "# Step 5: Evaluate the Model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on test data: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>\n",
    "Efficient Net\n",
    "</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abbas\\.conda\\envs\\Uni\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading model.safetensors: 100%|██████████| 21.4M/21.4M [00:08<00:00, 2.47MB/s]\n",
      "c:\\Users\\abbas\\.conda\\envs\\Uni\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\abbas\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.35642151709959313\n",
      "Epoch 2, Loss: 0.32512097746708524\n",
      "Epoch 3, Loss: 0.3245386958613881\n",
      "Epoch 4, Loss: 0.3089955276948119\n",
      "Epoch 5, Loss: 0.3120388691503984\n",
      "Epoch 6, Loss: 0.32582573278298166\n",
      "Epoch 7, Loss: 0.3046195779868218\n",
      "Epoch 8, Loss: 0.3094801496451229\n",
      "Epoch 9, Loss: 0.30638638262024154\n",
      "Epoch 10, Loss: 0.2987865160243606\n",
      "Epoch 11, Loss: 0.30875881570200936\n",
      "Epoch 12, Loss: 0.30699448909291993\n",
      "Epoch 13, Loss: 0.29874549828968305\n",
      "Epoch 14, Loss: 0.29450577959335206\n",
      "Epoch 15, Loss: 0.2969128592736105\n",
      "Epoch 16, Loss: 0.2925247289690442\n",
      "Epoch 17, Loss: 0.2927436823073816\n",
      "Epoch 18, Loss: 0.2952354799568321\n",
      "Epoch 19, Loss: 0.2882362373699486\n",
      "Epoch 20, Loss: 0.2879624851740426\n",
      "Epoch 21, Loss: 0.29062120628207366\n",
      "Epoch 22, Loss: 0.29599023367309435\n",
      "Epoch 23, Loss: 0.2872335499699563\n",
      "Epoch 24, Loss: 0.29192058513889635\n",
      "Epoch 25, Loss: 0.2867845134137953\n",
      "Epoch 26, Loss: 0.28595708265249725\n",
      "Epoch 27, Loss: 0.2868308588571597\n",
      "Epoch 28, Loss: 0.2827350831275536\n",
      "Epoch 29, Loss: 0.2852227113947106\n",
      "Epoch 30, Loss: 0.2836880919984005\n",
      "Epoch 31, Loss: 0.2785675504165234\n",
      "Epoch 32, Loss: 0.2794161328152653\n",
      "Epoch 33, Loss: 0.27694148322408085\n",
      "Epoch 34, Loss: 0.26778052763175564\n",
      "Epoch 35, Loss: 0.2917809339679888\n",
      "Epoch 36, Loss: 0.2820426067718232\n",
      "Epoch 37, Loss: 0.2883774627443251\n",
      "Epoch 38, Loss: 0.2810620994455974\n",
      "Epoch 39, Loss: 0.27496823854398217\n",
      "Epoch 40, Loss: 0.28189670989899224\n",
      "Epoch 41, Loss: 0.2802986646465763\n",
      "Epoch 42, Loss: 0.2693564104034001\n",
      "Epoch 43, Loss: 0.27715269837625406\n",
      "Epoch 44, Loss: 0.2699640490820971\n",
      "Epoch 45, Loss: 0.268498504226231\n",
      "Epoch 46, Loss: 0.2717542942668758\n",
      "Epoch 47, Loss: 0.2750180676531005\n",
      "Epoch 48, Loss: 0.26583198597481594\n",
      "Epoch 49, Loss: 0.26318684311022766\n",
      "Epoch 50, Loss: 0.275776747984597\n",
      "Epoch 51, Loss: 0.26870905587858207\n",
      "Epoch 52, Loss: 0.2716505767147448\n",
      "Epoch 53, Loss: 0.2636344069130303\n",
      "Epoch 54, Loss: 0.26356546272658726\n",
      "Epoch 55, Loss: 0.27196513793559324\n",
      "Epoch 56, Loss: 0.2794792899224893\n",
      "Epoch 57, Loss: 0.2522398788294994\n",
      "Epoch 58, Loss: 0.2780632599911282\n",
      "Epoch 59, Loss: 0.2565622238397294\n",
      "Epoch 60, Loss: 0.27601840198178496\n",
      "Epoch 61, Loss: 0.2587695648014324\n",
      "Epoch 62, Loss: 0.26998872508305266\n",
      "Epoch 63, Loss: 0.2547584581413898\n",
      "Epoch 64, Loss: 0.2537853510333675\n",
      "Epoch 65, Loss: 0.2723572585094706\n",
      "Epoch 66, Loss: 0.25949402190883364\n",
      "Epoch 67, Loss: 0.2504106024314812\n",
      "Epoch 68, Loss: 0.25461114022783854\n",
      "Epoch 69, Loss: 0.2624833336079209\n",
      "Epoch 70, Loss: 0.25506873310415495\n",
      "Epoch 71, Loss: 0.245596444736266\n",
      "Epoch 72, Loss: 0.2517644271676924\n",
      "Epoch 73, Loss: 0.2644199443406332\n",
      "Epoch 74, Loss: 0.2405056581385849\n",
      "Epoch 75, Loss: 0.2691813381735\n",
      "Epoch 76, Loss: 0.27607414612484243\n",
      "Epoch 77, Loss: 0.2492118116868937\n",
      "Epoch 78, Loss: 0.262097400526575\n",
      "Epoch 79, Loss: 0.2379282519539825\n",
      "Epoch 80, Loss: 0.2537902784378001\n",
      "Epoch 81, Loss: 0.24124790571256088\n",
      "Epoch 82, Loss: 0.2711107398670679\n",
      "Epoch 83, Loss: 0.2520922215925495\n",
      "Epoch 84, Loss: 0.2404561917467188\n",
      "Epoch 85, Loss: 0.2419799994919657\n",
      "Epoch 86, Loss: 0.22830239612761483\n",
      "Epoch 87, Loss: 0.2461763377678771\n",
      "Epoch 88, Loss: 0.2377347868960697\n",
      "Epoch 89, Loss: 0.21982306156473644\n",
      "Epoch 90, Loss: 0.24715218901440336\n",
      "Epoch 91, Loss: 0.24373553612106738\n",
      "Epoch 92, Loss: 0.23774560443108356\n",
      "Epoch 93, Loss: 0.24234394332719447\n",
      "Epoch 94, Loss: 0.24308679589385437\n",
      "Epoch 95, Loss: 0.23768396126833435\n",
      "Epoch 96, Loss: 0.23013610671513254\n",
      "Epoch 97, Loss: 0.2452092888595391\n",
      "Epoch 98, Loss: 0.24452840718250293\n",
      "Epoch 99, Loss: 0.24104035318548683\n",
      "Epoch 100, Loss: 0.22624177372491602\n",
      "Finished Training\n",
      "Accuracy on test data: 94.04%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "\n",
    "# Step 1: Data Loading and Preprocessing\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = r'Data\\archive\\Master Folder'\n",
    "image_datasets = {x: datasets.ImageFolder(root=data_dir, transform=data_transforms[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "model_name = \"efficientnet_b0\"  # You can choose from different versions (e.g., efficientnet_b0, efficientnet_b1, etc.)\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_features, len(class_names))\n",
    "\n",
    "model = CustomCNN(len(class_names))\n",
    "\n",
    "# Step 3: Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Step 4: Training Loop\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(dataloaders['train'])}\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "# Step 5: Evaluate the Model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on test data: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>\n",
    "Vision Transformer\n",
    "</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3712931394370647\n",
      "Epoch 2, Loss: 0.30862404140868815\n",
      "Epoch 3, Loss: 0.31355870294568156\n",
      "Epoch 4, Loss: 0.3170904924947644\n",
      "Epoch 5, Loss: 0.29737916739041254\n",
      "Epoch 6, Loss: 0.3037817850639718\n",
      "Epoch 7, Loss: 0.2943939291196962\n",
      "Epoch 8, Loss: 0.297940052509114\n",
      "Epoch 9, Loss: 0.29025053170589266\n",
      "Epoch 10, Loss: 0.2951931193761777\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "\n",
    "# Step 1: Data Loading and Preprocessing\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = r'Data\\archive\\Master Folder'\n",
    "image_datasets = {x: datasets.ImageFolder(root=data_dir, transform=data_transforms[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Step 2: Load a Pre-trained Vision Transformer (ViT) Model\n",
    "model_name = \"vit_base_patch16_224\"  # You can choose from different ViT models\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "num_features = model.head.in_features\n",
    "model.head = nn.Linear(num_features, len(class_names))\n",
    "\n",
    "\n",
    "# Step 3: Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Step 4: Training Loop\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(dataloaders['train'])}\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "# Step 5: Evaluate the Model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on test data: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
